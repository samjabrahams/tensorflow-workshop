{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating our own AlexNet from pre-built weights!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Weights from Michael Guerzhoy and Davi Frossard\n",
    "# http://www.cs.toronto.edu/~guerzhoy/tf_alexnet/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![AlexNet](images/alexnet_architecture.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Python > 3, TensorFlow > 1.0\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pretrained Variables from .npy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using original data\n"
     ]
    }
   ],
   "source": [
    "variable_data = np.load(\"saved_models/bvlc_alexnet.npy\", encoding='bytes').item()\n",
    "#variable_data2 = np.load(\"bvlc_alexnet.npy\", encoding='bytes').item()\n",
    "\n",
    "try:\n",
    "    if variable_data2:\n",
    "        old_idx = ['conv3/W', 'conv4/W', 'fc6/b', 'conv2/W', 'fc7/W', 'conv5/b', 'fc8/b', 'conv1/W', 'fc6/W', 'conv2/b', 'conv4/b', 'fc8/W', 'conv1/b', 'conv5/W', 'fc7/b', 'conv3/b']\n",
    "        new_idx = ['conv3', 'conv4', 'fc6', 'conv2', 'fc7', 'conv5', 'fc8', 'conv1', 'fc6', 'conv2', 'conv4', 'fc8', 'conv1', 'conv5', 'fc7', 'conv3']\n",
    "        variable_data = {}\n",
    "        for nidx in  new_idx:\n",
    "            variable_data[nidx] = [None,None]\n",
    "            variable_data[nidx][0] = variable_data2[nidx+'/W'][1]\n",
    "            variable_data[nidx][1] = variable_data2[nidx+'/b'] \n",
    "            print (variable_data[nidx][0].shape,variable_data[nidx][1].shape)\n",
    "    print (type(variable_data2))\n",
    "except:\n",
    "    print (\"using original data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['conv4', 'conv2', 'conv5', 'fc7', 'conv1', 'conv3', 'fc6', 'fc8'])\n"
     ]
    }
   ],
   "source": [
    "print (type(variable_data))\n",
    "print (variable_data.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11, 11, 3, 96)\n",
      "(96,)\n"
     ]
    }
   ],
   "source": [
    "conv1_preW = variable_data[\"conv1\"][0]\n",
    "conv1_preb = variable_data[\"conv1\"][1]\n",
    "print(conv1_preW.shape)\n",
    "print(conv1_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 5, 48, 256)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "conv2_preW = variable_data[\"conv2\"][0]\n",
    "conv2_preb = variable_data[\"conv2\"][1]\n",
    "print(conv2_preW.shape)\n",
    "print(conv2_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 256, 384)\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "conv3_preW = variable_data[\"conv3\"][0]\n",
    "conv3_preb = variable_data[\"conv3\"][1]\n",
    "print(conv3_preW.shape)\n",
    "print(conv3_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 192, 384)\n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "conv4_preW = variable_data[\"conv4\"][0]\n",
    "conv4_preb = variable_data[\"conv4\"][1]\n",
    "print(conv4_preW.shape)\n",
    "print(conv4_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 192, 256)\n",
      "(256,)\n"
     ]
    }
   ],
   "source": [
    "conv5_preW = variable_data[\"conv5\"][0]\n",
    "conv5_preb = variable_data[\"conv5\"][1]\n",
    "print(conv5_preW.shape)\n",
    "print(conv5_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9216, 4096)\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "fc6_preW = variable_data[\"fc6\"][0]\n",
    "fc6_preb = variable_data[\"fc6\"][1]\n",
    "print(fc6_preW.shape)\n",
    "print(fc6_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 4096)\n",
      "(4096,)\n"
     ]
    }
   ],
   "source": [
    "fc7_preW = variable_data[\"fc7\"][0]\n",
    "fc7_preb = variable_data[\"fc7\"][1]\n",
    "print(fc7_preW.shape)\n",
    "print(fc7_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 1000)\n",
      "(1000,)\n"
     ]
    }
   ],
   "source": [
    "fc8_preW = variable_data[\"fc8\"][0]\n",
    "fc8_preb = variable_data[\"fc8\"][1]\n",
    "print(fc8_preW.shape)\n",
    "print(fc8_preb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cat_dog_queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the huge AlexNet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pixel_depth = 255.0\n",
    "resized_height = 227\n",
    "resized_width = 227\n",
    "num_channels = 3\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "    x = tf.placeholder(tf.uint8, [None, None, None, num_channels],\n",
    "                       name='input')\n",
    "    \n",
    "    to_float = tf.cast(x, tf.float32)\n",
    "    resized = tf.image.resize_images(to_float, (resized_height, resized_width))\n",
    "    \n",
    "    # Convolution 1\n",
    "    with tf.name_scope('conv1') as scope:\n",
    "        kernel = tf.Variable(conv1_preW, name='weights')\n",
    "        biases = tf.Variable(conv1_preb, name='biases')\n",
    "        conv = tf.nn.conv2d(resized, kernel, [1, 4, 4, 1], padding=\"SAME\")\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "    # Local response normalization 2\n",
    "    radius = 2\n",
    "    alpha = 2e-05\n",
    "    beta = 0.75\n",
    "    bias = 1.0\n",
    "    lrn1 = tf.nn.local_response_normalization(conv1,\n",
    "                                              depth_radius=radius,\n",
    "                                              alpha=alpha,\n",
    "                                              beta=beta,\n",
    "                                              bias=bias)\n",
    "\n",
    "    # Maxpool 1\n",
    "    pool1 = tf.nn.max_pool(lrn1,\n",
    "                           ksize=[1, 3, 3, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='VALID',\n",
    "                           name='pool1')\n",
    "\n",
    "    # Convolution 2\n",
    "    with tf.name_scope('conv2') as scope:\n",
    "\n",
    "        kernel = tf.Variable(conv2_preW, name='weights')\n",
    "        biases = tf.Variable(conv2_preb, name='biases')\n",
    "\n",
    "        input_a, input_b = tf.split(axis=3,\n",
    "                                    num_or_size_splits=2,\n",
    "                                    value=pool1)\n",
    "        kernel_a, kernel_b = tf.split(axis=3,\n",
    "                                      num_or_size_splits=2,\n",
    "                                      value=kernel)\n",
    "\n",
    "        with tf.name_scope('A'):\n",
    "            conv_a = tf.nn.conv2d(input_a, kernel_a, [1, 1, 1, 1], padding=\"SAME\")        \n",
    "\n",
    "        with tf.name_scope('B'):\n",
    "            conv_b = tf.nn.conv2d(input_b, kernel_b, [1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "        conv = tf.concat(axis=3, values=[conv_a, conv_b])\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "    # Local response normalization 2\n",
    "    radius = 2\n",
    "    alpha = 2e-05\n",
    "    beta = 0.75\n",
    "    bias = 1.0\n",
    "    lrn2 = tf.nn.local_response_normalization(conv2,\n",
    "                                              depth_radius=radius,\n",
    "                                              alpha=alpha,\n",
    "                                              beta=beta,\n",
    "                                              bias=bias)\n",
    "\n",
    "    # Maxpool 2\n",
    "    pool2 = tf.nn.max_pool(lrn2,\n",
    "                           ksize=[1, 3, 3, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='VALID',\n",
    "                           name='pool2')\n",
    "\n",
    "    with tf.name_scope('conv3') as scope:\n",
    "        kernel = tf.Variable(conv3_preW, name='weights')\n",
    "        biases = tf.Variable(conv3_preb, name='biases')\n",
    "        conv = tf.nn.conv2d(pool2, kernel, [1, 1, 1, 1], padding=\"SAME\")\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv3 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "\n",
    "    with tf.name_scope('conv4') as scope:\n",
    "\n",
    "        kernel = tf.Variable(conv4_preW, name='weights')\n",
    "        biases = tf.Variable(conv4_preb, name='biases')\n",
    "\n",
    "        input_a, input_b = tf.split(axis=3,\n",
    "                                    num_or_size_splits=2,\n",
    "                                    value=conv3)\n",
    "        kernel_a, kernel_b = tf.split(axis=3,\n",
    "                                      num_or_size_splits=2,\n",
    "                                      value=kernel)\n",
    "\n",
    "        with tf.name_scope('A'):\n",
    "            conv_a = tf.nn.conv2d(input_a, kernel_a, [1, 1, 1, 1], padding=\"SAME\")        \n",
    "\n",
    "        with tf.name_scope('B'):\n",
    "            conv_b = tf.nn.conv2d(input_b, kernel_b, [1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "        conv = tf.concat(axis=3, values=[conv_a, conv_b])\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv4 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "\n",
    "    with tf.name_scope('conv5') as scope:\n",
    "\n",
    "        kernel = tf.Variable(conv5_preW, name='weights')\n",
    "        biases = tf.Variable(conv5_preb, name='biases')\n",
    "\n",
    "        input_a, input_b = tf.split(axis=3,\n",
    "                                    num_or_size_splits=2,\n",
    "                                    value=conv4)\n",
    "        kernel_a, kernel_b = tf.split(axis=3,\n",
    "                                      num_or_size_splits=2,\n",
    "                                      value=kernel)\n",
    "\n",
    "        with tf.name_scope('A'):\n",
    "            conv_a = tf.nn.conv2d(input_a, kernel_a, [1, 1, 1, 1], padding=\"SAME\")        \n",
    "\n",
    "        with tf.name_scope('B'):\n",
    "            conv_b = tf.nn.conv2d(input_b, kernel_b, [1, 1, 1, 1], padding=\"SAME\")\n",
    "\n",
    "        conv = tf.concat(axis=3, values=[conv_a, conv_b])\n",
    "        bias = tf.nn.bias_add(conv, biases)\n",
    "        conv5 = tf.nn.relu(bias, name=scope)\n",
    "\n",
    "\n",
    "    # Maxpool 2\n",
    "    pool5 = tf.nn.max_pool(conv5,\n",
    "                           ksize=[1, 3, 3, 1],\n",
    "                           strides=[1, 2, 2, 1],\n",
    "                           padding='VALID',\n",
    "                           name='pool5')\n",
    "\n",
    "    # Fully connected 6\n",
    "    with tf.name_scope('fc6'):\n",
    "        weights = tf.Variable(fc6_preW, name='fc6_weights')\n",
    "        bias = tf.Variable(fc6_preb, name='fc6_bias')\n",
    "        shape = tf.shape(pool5)\n",
    "        size = shape[1] * shape[2] * shape[3]\n",
    "        fc6 = tf.nn.relu_layer(tf.reshape(pool5, [-1, size]),\n",
    "                               weights, bias, name='relu')\n",
    "\n",
    "    # Fully connected 7\n",
    "    with tf.name_scope('fc7'):\n",
    "        weights = tf.Variable(fc7_preW, name='weights')\n",
    "        bias = tf.Variable(fc7_preb, name='bias')\n",
    "        fc7 = tf.nn.relu_layer(fc6, weights, bias, name='relu')\n",
    "\n",
    "    # Fully connected 8\n",
    "    with tf.name_scope('fc8'):\n",
    "        weights = tf.Variable(fc8_preW, name='weights')\n",
    "        bias = tf.Variable(fc8_preb, name='bias')\n",
    "        # fc8 = tf.matmul(fc7, weights) + bias\n",
    "        fc8 = tf.nn.xw_plus_b(fc7, weights, bias)\n",
    "\n",
    "    softmax = tf.nn.softmax(fc8)\n",
    "\n",
    "    init = tf.global_variables_initializer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session(graph=graph)\n",
    "sess.run(init)\n",
    "\n",
    "writer = tf.summary.FileWriter('tensorboard/alexnet', graph=graph)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the Entire Model\n",
    "\n",
    "[Check out the official tutorial for more details](https://www.tensorflow.org/versions/master/how_tos/meta_graph/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, 'saved_models/alex_vars')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
